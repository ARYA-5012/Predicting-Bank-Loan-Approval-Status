# -*- coding: utf-8 -*-
"""BIG DATA PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UAnipEoxR5uGZ4yYuZP-pXTSIauB_Ihl
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, mean, when
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler
from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, LinearSVC
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.mllib.evaluation import MulticlassMetrics
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

spark_session = SparkSession.builder.appName("BankLoanApproval").getOrCreate()

dataset_path = "lad1.2.csv"
loan_data = spark_session.read.csv(dataset_path, header=True, inferSchema=True)

loan_data = loan_data.drop("Unnamed: 0", "Loan_ID")

loan_data.printSchema()
loan_data.show(5)

from pyspark.sql.functions import col, mean
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler

num_features = ["LoanAmount", "Loan_Amount_Term", "Credit_History"]
for feature in num_features:
    avg_value = loan_data.select(mean(col(feature))).collect()[0][0]
    loan_data = loan_data.fillna({feature: avg_value})

cat_features = ["Gender", "Married", "Dependents", "Self_Employed"]
for feature in cat_features:
    most_frequent = loan_data.groupBy(feature).count().orderBy("count", ascending=False).first()[0]
    loan_data = loan_data.fillna({feature: most_frequent})

index_transformer = StringIndexer(
    inputCols=["Gender", "Married", "Dependents", "Education",
               "Self_Employed", "Property_Area", "Loan_Status"],
    outputCols=["Gender_idx", "Married_idx", "Dependents_idx",
                "Education_idx", "Self_Employed_idx",
                "Property_Area_idx", "Loan_Status_idx"]
)
loan_data = index_transformer.fit(loan_data).transform(loan_data)

encoder_transformer = OneHotEncoder(
    inputCols=["Gender_idx", "Married_idx", "Dependents_idx",
               "Education_idx", "Self_Employed_idx",
               "Property_Area_idx"],
    outputCols=["Gender_vec", "Married_vec", "Dependents_vec",
                "Education_vec", "Self_Employed_vec",
                "Property_Area_vec"]
)
loan_data = encoder_transformer.fit(loan_data).transform(loan_data)

loan_data = loan_data.withColumn("Combined_Income", col("ApplicantIncome") + col("CoapplicantIncome"))
loan_data = loan_data.withColumn("Income_Loan_Ratio", col("Combined_Income") / col("LoanAmount"))

input_features = ["LoanAmount", "Loan_Amount_Term", "Credit_History",
                  "Combined_Income", "Income_Loan_Ratio",
                  "Gender_vec", "Married_vec", "Dependents_vec",
                  "Education_vec", "Self_Employed_vec", "Property_Area_vec"]

assembler = VectorAssembler(inputCols=input_features, outputCol="raw_features")
loan_data = assembler.transform(loan_data)

scaler = StandardScaler(inputCol="raw_features", outputCol="scaled_features")
loan_data = scaler.fit(loan_data).transform(loan_data)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

eda_df = loan_data.select(["Loan_Status", "Credit_History", "Combined_Income", "Property_Area"]).toPandas()

sns.countplot(data=eda_df, x="Loan_Status")
plt.title("Loan Status Distribution")
plt.show()

sns.boxplot(data=eda_df, x="Loan_Status", y="Combined_Income")
plt.title("Income Distribution by Loan Status")
plt.show()

sns.barplot(data=eda_df, x="Credit_History", y=eda_df["Loan_Status"].apply(lambda x: 1 if x == "Y" else 0))
plt.title("Loan Approval Rate by Credit History")
plt.show()

train_set, test_set = loan_data.randomSplit([0.8, 0.2], seed=42)

from pyspark.ml.evaluation import BinaryClassificationEvaluator
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

def plot_roc_curve(true_labels, predictions, model_name, color):
    fpr, tpr, _ = roc_curve(true_labels, predictions)
    roc_auc = auc(fpr, tpr)

    plt.figure(figsize=(6, 4))
    plt.plot(fpr, tpr, color=color, label=f'{model_name} (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
    plt.title(f"ROC Curve - {model_name}")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.legend(loc="lower right")
    plt.show()

evaluator_dt = BinaryClassificationEvaluator(labelCol="Loan_Status_idx", rawPredictionCol="prediction", metricName="areaUnderROC")
roc_auc_dt = evaluator_dt.evaluate(dt_predictions)
print(f"Decision Tree ROC AUC: {roc_auc_dt:.2f}")
dt_true_labels = dt_predictions.select("Loan_Status_idx").rdd.flatMap(lambda x: x).collect()  # Collect true labels

if 'probability' in dt_predictions.columns:
    dt_pred_scores = dt_predictions.select("probability").rdd.map(lambda row: row[0][1]).collect()
else:
    dt_pred_scores = dt_predictions.select("rawPrediction").rdd.map(lambda row: row[0][1]).collect()
plot_roc_curve(dt_true_labels, dt_pred_scores, "Decision Tree", "green")

evaluator_svm = BinaryClassificationEvaluator(labelCol="Loan_Status_idx", rawPredictionCol="prediction", metricName="areaUnderROC")
roc_auc_svm = evaluator_svm.evaluate(svm_predictions)
print(f"SVM ROC AUC: {roc_auc_svm:.2f}")
svm_true_labels = svm_predictions.select("Loan_Status_idx").rdd.flatMap(lambda x: x).collect()

if 'probability' in svm_predictions.columns:
    svm_pred_scores = svm_predictions.select("probability").rdd.map(lambda row: row[0][1]).collect()
else:
    svm_pred_scores = svm_predictions.select("rawPrediction").rdd.map(lambda row: row[0][1]).collect()
plot_roc_curve(svm_true_labels, svm_pred_scores, "SVM", "red")

evaluator_rf = BinaryClassificationEvaluator(labelCol="Loan_Status_idx", rawPredictionCol="prediction", metricName="areaUnderROC")
roc_auc_rf = evaluator_rf.evaluate(rf_predictions)
print(f"Random Forest ROC AUC: {roc_auc_rf:.2f}")
rf_true_labels = rf_predictions.select("Loan_Status_idx").rdd.flatMap(lambda x: x).collect()

if 'probability' in rf_predictions.columns:
    rf_pred_scores = rf_predictions.select("probability").rdd.map(lambda row: row[0][1]).collect()
else:
    rf_pred_scores = rf_predictions.select("rawPrediction").rdd.map(lambda row: row[0][1]).collect()
plot_roc_curve(rf_true_labels, rf_pred_scores, "Random Forest", "purple")

from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, LinearSVC
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

dt_model = DecisionTreeClassifier(labelCol="Loan_Status_idx", featuresCol="scaled_features").fit(train_set)
dt_predictions = dt_model.transform(test_set)

svm_model = LinearSVC(labelCol="Loan_Status_idx", featuresCol="scaled_features", maxIter=10).fit(train_set)
svm_predictions = svm_model.transform(test_set)

!pip install pyspark
!pip install pandas
!pip install matplotlib
!pip install seaborn
!pip install scikit-learn
!pip install knn-spark

rf_model = RandomForestClassifier(labelCol="Loan_Status_idx", featuresCol="scaled_features", numTrees=100).fit(train_set)
rf_predictions = rf_model.transform(test_set)

def evaluate_classifier(predictions, model_label):
    evaluator = MulticlassClassificationEvaluator(labelCol="Loan_Status_idx")
    accuracy = evaluator.evaluate(predictions, {evaluator.metricName: "accuracy"})
    precision = evaluator.evaluate(predictions, {evaluator.metricName: "weightedPrecision"})
    recall = evaluator.evaluate(predictions, {evaluator.metricName: "weightedRecall"})
    f1 = evaluator.evaluate(predictions, {evaluator.metricName: "f1"})

    print(f"{model_label} - Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}")

evaluate_classifier(dt_predictions, "Decision Tree")
evaluate_classifier(rf_predictions, "Random Forest")
evaluate_classifier(svm_predictions, "SVM")

from pyspark.mllib.evaluation import MulticlassMetrics

def display_confusion_matrix(predictions, model_label):
    pred_rdd = predictions.select("Loan_Status_idx", "prediction").rdd.map(tuple)
    metrics = MulticlassMetrics(pred_rdd)
    cm_matrix = metrics.confusionMatrix().toArray()

    sns.heatmap(cm_matrix, annot=True, fmt="g", cmap="coolwarm")
    plt.title(f"{model_label} - Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

display_confusion_matrix(dt_predictions, "Decision Tree")
display_confusion_matrix(rf_predictions, "Random Forest")
display_confusion_matrix(svm_predictions, "SVM")

metadata_features = loan_data.schema["raw_features"].metadata["ml_attr"]["attrs"]
feature_list = [attr["name"] for attr_type in metadata_features.values() for attr in attr_type]

print(f"Extracted Features: {feature_list}")
print(f"Total Features: {len(feature_list)}")

feature_importance_df = pd.DataFrame({
    "Feature": feature_list,
    "Importance": dt_model.featureImportances.toArray()
})

feature_importance_df = feature_importance_df.sort_values(by="Importance", ascending=False)

sns.barplot(data=feature_importance_df, x="Importance", y="Feature", palette="coolwarm")
plt.title("Feature Importance from Decision Tree")
plt.xlabel("Importance")
plt.ylabel("Features")
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Model metrics
models = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'SVM', 'KNN']
accuracy = [0.78, 0.76, 0.88, 0.82, 0.74]
precision = [0.75, 0.74, 0.87, 0.80, 0.72]
recall = [0.80, 0.78, 0.89, 0.81, 0.75]
f1_score = [0.77, 0.76, 0.88, 0.80, 0.73]
roc_auc = [0.82, 0.79, 0.90, 0.83, 0.76]

# Plot metrics
x = np.arange(len(models))
width = 0.15  # width of the bars

fig, ax = plt.subplots(figsize=(10, 6))
ax.bar(x - 2*width, accuracy, width, label='Accuracy')
ax.bar(x - width, precision, width, label='Precision')
ax.bar(x, recall, width, label='Recall')
ax.bar(x + width, f1_score, width, label='F1-Score')
ax.bar(x + 2*width, roc_auc, width, label='ROC-AUC')

# Customize the plot
ax.set_xlabel('Models')
ax.set_ylabel('Metrics')
ax.set_title('Comparative Analysis of ML Models')
ax.set_xticks(x)
ax.set_xticklabels(models)
ax.legend()

# Show the plot
plt.tight_layout()
plt.show()





